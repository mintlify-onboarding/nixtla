---
title: "FugueBackend"
description: "The computational efficiency of `StatsForecast` can be tracked to its two core components:

1. Its `models` written in NumBa that optimizes Python code to reach C speeds.

2. Its `core.StatsForecast` class that enables distributed computing."
---

Here we use [Fugue](https://github.com/fugue-project/fugue) which is a unified interface for `Dask` and `Spark`.

## FugueBackend

```
 FugueBackend (engine:Any=None, conf:Any=None, **transform_kwargs:Any)
```

FugueBackend for Distributed Computation. [Source code.](https://github.com/Nixtla/statsforecast/blob/main/statsforecast/distributed/fugue.py)

This class uses [Fugue](https://github.com/fugue-project/fugue) backend capable of distributing computation on Spark and Dask without any rewrites.

**Parameters:**

`engine`: fugue.ExecutionEngine, a selection between spark and dask.

`conf`: fugue.Config, engine configuration.

`**transform_kwargs`: additional kwargs for Fugue’s transform method.

**Notes:** 

A short introduction to Fugue, with examples on how to scale pandas code to scale pandas based code to Spark or Dask is available [here](https://fugue-tutorials.readthedocs.io/tutorials/quick_look/ten_minutes.html).


## Dask Distributed Predictions

Here we provide an example for the distribution of the [`StatsForecast`](/statsforecast/api-reference/core#statsforecast) predictions using `Fugue` to execute the code in a Dask cluster

To do it we instantiate the [`FugueBackend`](#FugureBackend) class with a `DaskExecutionEngine`.

```python 
import dask.dataframe as dd
from dask.distributed import Client
from fugue_dask import DaskExecutionEngine
from statsforecast import StatsForecast
from statsforecast.models import Naive
from statsforecast.utils import generate_series

# Generate Synthetic Panel Data
df = generate_series(10).reset_index()
df['unique_id'] = df['unique_id'].astype(str)
df = dd.from_pandas(df, npartitions=10)

# Instantiate FugueBackend with DaskExecutionEngine
dask_client = Client()
engine = DaskExecutionEngine(dask_client=dask_client)
```

We have simply create the class to the usual [`StatsForecast`](/statsforecast/api-reference/core#statsforecast) instantiation.

```python 
sf = StatsForecast(models=[Naive()], freq='D')
```

### Distributed Forecast

For extremely fast distributed predictions we use FugueBackend as backend that operates like the original [StatsForecast.forecast](/statsforecast/api-reference/core#statsforecast.forecast) method.

It receives as input a pandas.DataFrame with columns [`unique_id`,`ds`,`y`] and exogenous, where the `ds` (datestamp) column should be of a format expected by Pandas. The `y` column must be numeric, and represents the measurement we wish to forecast. And the `unique_id` uniquely identifies the series in the panel data.

```python 
# Distributed predictions with FugueBackend.
sf.forecast(df=df, h=12).compute()
```

### Distributed Cross-Validation

For extremely fast distributed temporcal `cross-validation` we use cross_validation method that operates like the original [StatsForecast.cross_validation](/statsforecast/api-reference/core#statsforecast.cross_validation) method.

```python 
# Distributed cross-validation with FugueBackend.
sf.cross_validation(df=df, h=12, n_windows=2).compute()
```


Give us a ⭐ on [Github](https://github.com/nixtla/statsforecast)




